# 并发安全性评估和优化方案

## 🔴 当前问题分析

### 1. 防重复提交机制缺失 ⚠️ **高风险**

**问题描述**：
- `create_ai_task()` 函数没有检查订单是否已有任务
- `create_api_task()` 函数没有检查是否重复提交
- 同一个订单可能被多次处理，导致重复任务

**影响**：
- 同一订单可能创建多个AI任务
- 浪费API额度
- 产生重复的结果图片

**代码位置**：
- `app/services/workflow_service.py` - `create_ai_task()` (第298行)
- `app/services/ai_provider_service.py` - `create_api_task()` (第310行)

**当前代码**：
```python
# 直接创建任务，没有检查是否已存在
ai_task = AITask(
    order_id=order_id,
    ...
)
db.session.add(ai_task)
db.session.commit()
```

### 2. 数据库锁机制缺失 ⚠️ **高风险**

**问题描述**：
- 没有使用 `select_for_update()` 或类似机制
- 多个请求可能同时读取和更新同一订单/任务
- SQLite在高并发写入时可能出现锁等待或死锁

**影响**：
- 任务状态更新可能丢失
- 数据库写入冲突
- 数据不一致

**代码位置**：
- 所有 `db.session.commit()` 操作都没有加锁
- 任务状态更新没有使用悲观锁

### 3. 任务队列系统缺失 ⚠️ **中风险**

**问题描述**：
- 任务直接提交到ComfyUI/API，没有队列管理
- 高并发时可能导致：
  - ComfyUI/API过载
  - 请求超时
  - 服务不稳定

**影响**：
- 几十上百个任务同时提交时，可能导致：
  - ComfyUI服务器过载
  - API服务商限流
  - 任务失败率增加

### 4. 任务状态更新并发问题 ⚠️ **中风险**

**问题描述**：
- 多个轮询可能同时更新任务状态
- 没有使用乐观锁或悲观锁
- 可能导致状态覆盖

**影响**：
- 任务状态可能被错误覆盖
- 轮询结果可能丢失

### 5. SQLite并发限制 ⚠️ **高风险**

**问题描述**：
- SQLite在高并发写入时性能较差
- 默认的WAL模式虽然支持并发，但仍有写入锁
- 几十上百个任务同时提交时，可能出现：
  - 数据库锁等待
  - 写入超时
  - 性能下降

## 📊 风险评估

### 低并发场景（< 10个任务/分钟）
- ✅ **风险较低**：SQLite可以正常处理
- ⚠️ **仍需优化**：防重复提交机制

### 中并发场景（10-50个任务/分钟）
- ⚠️ **风险中等**：可能出现数据库锁等待
- ⚠️ **需要优化**：防重复提交、数据库锁

### 高并发场景（50-100+个任务/分钟）
- 🔴 **风险高**：可能出现以下问题：
  - 数据库写入冲突
  - 重复任务创建
  - ComfyUI/API过载
  - 任务状态更新丢失

## ✅ 优化方案

### 方案1：防重复提交机制（必须实现）

#### 1.1 ComfyUI工作流任务防重复

**修改文件**：`app/services/workflow_service.py`

```python
def create_ai_task(order_id, style_category_id, style_image_id=None, ...):
    # 在创建任务前，检查是否已有相同订单的待处理/处理中任务
    existing_task = AITask.query.filter_by(
        order_id=order_id,
        status.in_(['pending', 'processing'])
    ).first()
    
    if existing_task:
        # 如果已有任务，返回现有任务
        return True, existing_task, None
    
    # 创建新任务
    ...
```

#### 1.2 API任务防重复

**修改文件**：`app/services/ai_provider_service.py`

```python
def create_api_task(style_image_id, prompt, ...):
    # 检查是否已有相同风格图片的待处理/处理中任务
    # 注意：API任务可能没有order_id，需要根据业务逻辑判断
    # 如果有关联订单，检查订单是否已有任务
    ...
```

### 方案2：数据库锁机制（必须实现）

#### 2.1 使用悲观锁（推荐）

**修改文件**：`app/services/workflow_service.py`

```python
from sqlalchemy import select

def create_ai_task(order_id, ...):
    # 使用悲观锁查询订单
    order = db.session.execute(
        select(Order).where(Order.id == order_id).with_for_update()
    ).scalar_one_or_none()
    
    # 检查是否已有任务（在锁内检查）
    existing_task = db.session.execute(
        select(AITask).where(
            AITask.order_id == order_id,
            AITask.status.in_(['pending', 'processing'])
        ).with_for_update()
    ).scalar_one_or_none()
    
    if existing_task:
        return True, existing_task, None
    
    # 创建新任务
    ...
```

#### 2.2 使用乐观锁（备选）

**修改文件**：`app/models.py`

```python
class AITask(db.Model):
    ...
    version = db.Column(db.Integer, default=0)  # 版本号
    
    def update_status(self, new_status, db):
        """使用乐观锁更新状态"""
        current_version = self.version
        self.status = new_status
        self.version += 1
        
        # 检查版本号是否变化
        updated = db.session.execute(
            update(AITask)
            .where(AITask.id == self.id, AITask.version == current_version)
            .values(status=new_status, version=self.version + 1)
        ).rowcount
        
        if updated == 0:
            raise Exception("任务状态已被其他进程更新，请重试")
```

### 方案3：任务队列系统（推荐实现）

#### 3.1 使用Celery（生产环境推荐）

**优点**：
- 成熟的任务队列系统
- 支持分布式
- 支持任务重试
- 支持任务优先级

**缺点**：
- 需要额外的Redis/RabbitMQ
- 配置较复杂

#### 3.2 使用简单队列（快速实现）

**实现方式**：
```python
import queue
import threading

# 创建任务队列
task_queue = queue.Queue(maxsize=100)  # 最大100个任务排队

def process_task_queue():
    """处理任务队列"""
    while True:
        try:
            task_data = task_queue.get(timeout=1)
            # 处理任务
            create_ai_task(**task_data)
            task_queue.task_done()
        except queue.Empty:
            continue

# 启动后台线程
worker_thread = threading.Thread(target=process_task_queue, daemon=True)
worker_thread.start()
```

### 方案4：限流机制（推荐实现）

#### 4.1 API调用限流

```python
from threading import Semaphore
import time

# 创建信号量，限制并发数
api_semaphore = Semaphore(5)  # 最多5个并发API调用

def create_api_task(...):
    # 获取信号量
    api_semaphore.acquire()
    try:
        # 调用API
        response = call_api_with_config(...)
    finally:
        # 释放信号量
        api_semaphore.release()
```

#### 4.2 ComfyUI调用限流

```python
comfyui_semaphore = Semaphore(10)  # 最多10个并发ComfyUI调用

def create_ai_task(...):
    comfyui_semaphore.acquire()
    try:
        # 提交到ComfyUI
        response = requests.post(comfyui_url, ...)
    finally:
        comfyui_semaphore.release()
```

### 方案5：任务状态更新优化（必须实现）

#### 5.1 使用数据库锁更新状态

```python
def update_task_status(task_id, new_status, db, AITask):
    """使用锁更新任务状态"""
    task = db.session.execute(
        select(AITask).where(AITask.id == task_id).with_for_update()
    ).scalar_one_or_none()
    
    if not task:
        return False
    
    # 检查状态转换是否合法
    if task.status in ['completed', 'failed']:
        # 已完成的任务不再更新
        return False
    
    task.status = new_status
    db.session.commit()
    return True
```

## 🎯 实施优先级

### 高优先级（立即实施）

1. ✅ **防重复提交机制**
   - 检查订单是否已有任务
   - 避免重复创建任务

2. ✅ **数据库锁机制**
   - 使用 `with_for_update()` 保护关键操作
   - 防止并发写入冲突

### 中优先级（尽快实施）

3. ⚠️ **限流机制**
   - API调用限流
   - ComfyUI调用限流

4. ⚠️ **任务状态更新优化**
   - 使用锁保护状态更新
   - 检查状态转换合法性

### 低优先级（长期优化）

5. ⚠️ **任务队列系统**
   - 使用Celery或简单队列
   - 支持任务优先级

## 📝 代码修改清单

### 必须修改的文件

1. `app/services/workflow_service.py`
   - 添加防重复提交检查
   - 添加数据库锁

2. `app/services/ai_provider_service.py`
   - 添加防重复提交检查
   - 添加限流机制

3. `app/models.py`
   - 考虑添加唯一约束（如果业务允许）

### 可选修改的文件

4. `app/services/image_processing_service.py`
   - 添加防重复处理检查

5. `test_server.py`
   - 配置数据库连接池
   - 设置SQLite WAL模式

## 🔍 测试建议

### 并发测试场景

1. **测试场景1：同一订单多次提交**
   - 模拟10个请求同时提交同一订单
   - 验证：只创建一个任务

2. **测试场景2：高并发任务提交**
   - 模拟100个任务同时提交
   - 验证：所有任务都能正常创建，无重复

3. **测试场景3：任务状态更新并发**
   - 模拟多个轮询同时更新任务状态
   - 验证：状态更新正确，无覆盖

4. **测试场景4：数据库写入并发**
   - 模拟50个任务同时写入数据库
   - 验证：无锁等待超时，无数据丢失

## ⚠️ 注意事项

1. **SQLite限制**：
   - SQLite在高并发写入时性能较差
   - 如果并发量很大（>100任务/分钟），建议迁移到PostgreSQL或MySQL

2. **ComfyUI限制**：
   - ComfyUI服务器可能有并发限制
   - 需要根据服务器性能调整限流参数

3. **API服务商限制**：
   - 不同服务商有不同的限流策略
   - 需要根据服务商文档设置限流参数

---

**评估时间**：2025-01-XX  
**评估版本**：v1.0  
**风险等级**：🔴 **高风险**（高并发场景）
