#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
PostgreSQLæ•°æ®åº“å¤‡ä»½è„šæœ¬
æ”¯æŒè‡ªåŠ¨å¤‡ä»½ã€å¤‡ä»½å†å²ç®¡ç†ã€è‡ªåŠ¨æ¸…ç†æ—§å¤‡ä»½
"""

import os
import sys
import subprocess
import json
from datetime import datetime, timedelta
from pathlib import Path

# é»˜è®¤é…ç½®
DEFAULT_BACKUP_DIR = 'data/backups/postgresql'
DEFAULT_RETENTION_DAYS = 30  # ä¿ç•™30å¤©çš„å¤‡ä»½
DEFAULT_DB_NAME = 'pet_painting'
DEFAULT_DB_USER = 'aistudio_user'
DEFAULT_DB_HOST = 'localhost'
DEFAULT_DB_PORT = '5432'

class PostgreSQLBackup:
    """PostgreSQLæ•°æ®åº“å¤‡ä»½ç®¡ç†å™¨"""
    
    def __init__(self, backup_dir=None, retention_days=None, db_name=None, 
                 db_user=None, db_password=None, db_host=None, db_port=None):
        """
        åˆå§‹åŒ–å¤‡ä»½ç®¡ç†å™¨
        
        Args:
            backup_dir: å¤‡ä»½ç›®å½•è·¯å¾„
            retention_days: ä¿ç•™å¤©æ•°
            db_name: æ•°æ®åº“åç§°
            db_user: æ•°æ®åº“ç”¨æˆ·å
            db_password: æ•°æ®åº“å¯†ç 
            db_host: æ•°æ®åº“ä¸»æœº
            db_port: æ•°æ®åº“ç«¯å£
        """
        # ä»ç¯å¢ƒå˜é‡æˆ–å‚æ•°è·å–é…ç½®
        self.backup_dir = backup_dir or os.environ.get('PG_BACKUP_DIR', DEFAULT_BACKUP_DIR)
        self.retention_days = retention_days or int(os.environ.get('PG_BACKUP_RETENTION_DAYS', DEFAULT_RETENTION_DAYS))
        self.db_name = db_name or os.environ.get('PG_DATABASE', DEFAULT_DB_NAME)
        self.db_user = db_user or os.environ.get('PG_USER', DEFAULT_DB_USER)
        self.db_password = db_password or os.environ.get('PG_PASSWORD', '')
        self.db_host = db_host or os.environ.get('PG_HOST', DEFAULT_DB_HOST)
        self.db_port = db_port or os.environ.get('PG_PORT', DEFAULT_DB_PORT)
        
        # ä»DATABASE_URLè§£æï¼ˆå¦‚æœå­˜åœ¨ï¼‰
        database_url = os.environ.get('DATABASE_URL', '')
        if database_url and database_url.startswith('postgresql://'):
            self._parse_database_url(database_url)
        
        # ç¡®ä¿å¤‡ä»½ç›®å½•å­˜åœ¨
        os.makedirs(self.backup_dir, exist_ok=True)
        
        # æ—¥å¿—æ–‡ä»¶
        self.log_file = os.path.join(self.backup_dir, 'backup_log.json')
    
    def _parse_database_url(self, url):
        """ä»DATABASE_URLè§£ææ•°æ®åº“è¿æ¥ä¿¡æ¯"""
        try:
            # postgresql://user:password@host:port/database
            url = url.replace('postgresql://', '')
            if '@' in url:
                auth, rest = url.split('@', 1)
                if ':' in auth:
                    self.db_user, self.db_password = auth.split(':', 1)
                else:
                    self.db_user = auth
                
                if '/' in rest:
                    host_port, self.db_name = rest.rsplit('/', 1)
                    if ':' in host_port:
                        self.db_host, self.db_port = host_port.split(':', 1)
                    else:
                        self.db_host = host_port
        except Exception as e:
            print(f"âš ï¸  è§£æDATABASE_URLå¤±è´¥: {e}")
    
    def check_pg_dump(self):
        """æ£€æŸ¥pg_dumpå‘½ä»¤æ˜¯å¦å¯ç”¨"""
        try:
            result = subprocess.run(['pg_dump', '--version'], 
                                  capture_output=True, text=True, timeout=5)
            if result.returncode == 0:
                print(f"âœ… æ‰¾åˆ° pg_dump: {result.stdout.strip()}")
                return True
        except FileNotFoundError:
            print("âŒ é”™è¯¯: æœªæ‰¾åˆ° pg_dump å‘½ä»¤")
            print("   è¯·ç¡®ä¿PostgreSQLå·²å®‰è£…å¹¶æ·»åŠ åˆ°PATHç¯å¢ƒå˜é‡")
            print("   Windows: é€šå¸¸ä½äº C:\\Program Files\\PostgreSQL\\XX\\bin\\")
            print("   Linux: sudo apt-get install postgresql-client")
            return False
        except Exception as e:
            print(f"âŒ æ£€æŸ¥pg_dumpå¤±è´¥: {e}")
            return False
    
    def backup_database(self, backup_type='full'):
        """
        å¤‡ä»½æ•°æ®åº“
        
        Args:
            backup_type: å¤‡ä»½ç±»å‹
                - 'full': å®Œæ•´å¤‡ä»½ï¼ˆé»˜è®¤ï¼‰
                - 'schema': åªå¤‡ä»½è¡¨ç»“æ„
                - 'data': åªå¤‡ä»½æ•°æ®
        
        Returns:
            dict: å¤‡ä»½ä¿¡æ¯ï¼Œå¤±è´¥è¿”å›None
        """
        if not self.check_pg_dump():
            return None
        
        try:
            # ç”Ÿæˆå¤‡ä»½æ–‡ä»¶å
            timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
            if backup_type == 'schema':
                backup_filename = f"{self.db_name}_schema_{timestamp}.sql"
            elif backup_type == 'data':
                backup_filename = f"{self.db_name}_data_{timestamp}.sql"
            else:
                backup_filename = f"{self.db_name}_full_{timestamp}.sql"
            
            backup_path = os.path.join(self.backup_dir, backup_filename)
            
            # æ„å»ºpg_dumpå‘½ä»¤
            cmd = ['pg_dump']
            
            # æ·»åŠ è¿æ¥å‚æ•°
            if self.db_host:
                cmd.extend(['-h', self.db_host])
            if self.db_port:
                cmd.extend(['-p', str(self.db_port)])
            if self.db_user:
                cmd.extend(['-U', self.db_user])
            cmd.extend(['-d', self.db_name])
            
            # æ ¹æ®å¤‡ä»½ç±»å‹æ·»åŠ é€‰é¡¹
            if backup_type == 'schema':
                cmd.append('--schema-only')
            elif backup_type == 'data':
                cmd.append('--data-only')
            
            # æ·»åŠ å…¶ä»–é€‰é¡¹
            cmd.extend(['-F', 'p'])  # çº¯æ–‡æœ¬æ ¼å¼
            cmd.extend(['-f', backup_path])
            
            # è®¾ç½®ç¯å¢ƒå˜é‡ï¼ˆç”¨äºå¯†ç ï¼‰
            env = os.environ.copy()
            if self.db_password:
                env['PGPASSWORD'] = self.db_password
            
            print(f"ğŸ“¦ å¼€å§‹å¤‡ä»½æ•°æ®åº“: {self.db_name}")
            print(f"   å¤‡ä»½ç±»å‹: {backup_type}")
            print(f"   å¤‡ä»½æ–‡ä»¶: {backup_filename}")
            
            # æ‰§è¡Œå¤‡ä»½
            result = subprocess.run(cmd, env=env, capture_output=True, text=True, timeout=3600)
            
            if result.returncode != 0:
                print(f"âŒ å¤‡ä»½å¤±è´¥:")
                print(f"   é”™è¯¯ä¿¡æ¯: {result.stderr}")
                return None
            
            # è·å–æ–‡ä»¶å¤§å°
            file_size = os.path.getsize(backup_path)
            file_size_mb = file_size / (1024 * 1024)
            
            print(f"âœ… å¤‡ä»½æˆåŠŸ: {backup_filename}")
            print(f"   æ–‡ä»¶å¤§å°: {file_size_mb:.2f} MB ({file_size:,} å­—èŠ‚)")
            print(f"   ä¿å­˜ä½ç½®: {backup_path}")
            
            # è®°å½•å¤‡ä»½ä¿¡æ¯
            backup_info = {
                'backup_name': backup_filename,
                'backup_path': backup_path,
                'backup_type': backup_type,
                'database': self.db_name,
                'size': file_size,
                'size_mb': round(file_size_mb, 2),
                'timestamp': timestamp,
                'datetime': datetime.now().isoformat()
            }
            
            self.save_log(backup_info)
            
            return backup_info
            
        except subprocess.TimeoutExpired:
            print("âŒ å¤‡ä»½è¶…æ—¶ï¼ˆè¶…è¿‡1å°æ—¶ï¼‰")
            return None
        except Exception as e:
            print(f"âŒ å¤‡ä»½å¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
            return None
    
    def load_log(self):
        """åŠ è½½å¤‡ä»½æ—¥å¿—"""
        if os.path.exists(self.log_file):
            try:
                with open(self.log_file, 'r', encoding='utf-8') as f:
                    return json.load(f)
            except Exception as e:
                print(f"âš ï¸  åŠ è½½æ—¥å¿—å¤±è´¥: {e}")
        return []
    
    def save_log(self, backup_info):
        """ä¿å­˜å¤‡ä»½æ—¥å¿—"""
        try:
            log = self.load_log()
            log.append(backup_info)
            
            # åªä¿ç•™æœ€è¿‘Nå¤©çš„æ—¥å¿—
            cutoff_date = datetime.now() - timedelta(days=self.retention_days * 2)
            log = [l for l in log if datetime.fromisoformat(l['datetime']) > cutoff_date]
            
            with open(self.log_file, 'w', encoding='utf-8') as f:
                json.dump(log, f, ensure_ascii=False, indent=2)
        except Exception as e:
            print(f"âš ï¸  ä¿å­˜æ—¥å¿—å¤±è´¥: {e}")
    
    def cleanup_old_backups(self):
        """æ¸…ç†æ—§å¤‡ä»½æ–‡ä»¶"""
        try:
            cutoff_date = datetime.now() - timedelta(days=self.retention_days)
            deleted_count = 0
            deleted_size = 0
            
            for filename in os.listdir(self.backup_dir):
                if not filename.endswith('.sql'):
                    continue
                
                file_path = os.path.join(self.backup_dir, filename)
                
                # è·å–æ–‡ä»¶ä¿®æ”¹æ—¶é—´
                file_time = datetime.fromtimestamp(os.path.getmtime(file_path))
                
                if file_time < cutoff_date:
                    file_size = os.path.getsize(file_path)
                    os.remove(file_path)
                    deleted_count += 1
                    deleted_size += file_size
                    print(f"ğŸ—‘ï¸  åˆ é™¤æ—§å¤‡ä»½: {filename}")
            
            if deleted_count > 0:
                deleted_size_mb = deleted_size / (1024 * 1024)
                print(f"âœ… æ¸…ç†å®Œæˆ: åˆ é™¤äº† {deleted_count} ä¸ªæ—§å¤‡ä»½æ–‡ä»¶ ({deleted_size_mb:.2f} MB)")
            else:
                print("â„¹ï¸  æ²¡æœ‰éœ€è¦æ¸…ç†çš„æ—§å¤‡ä»½")
            
            return deleted_count, deleted_size
            
        except Exception as e:
            print(f"âš ï¸  æ¸…ç†æ—§å¤‡ä»½å¤±è´¥: {e}")
            return 0, 0
    
    def list_backups(self):
        """åˆ—å‡ºæ‰€æœ‰å¤‡ä»½æ–‡ä»¶"""
        try:
            backups = []
            total_size = 0
            
            for filename in os.listdir(self.backup_dir):
                if not filename.endswith('.sql'):
                    continue
                
                file_path = os.path.join(self.backup_dir, filename)
                file_size = os.path.getsize(file_path)
                file_time = datetime.fromtimestamp(os.path.getmtime(file_path))
                
                backups.append({
                    'filename': filename,
                    'size': file_size,
                    'size_mb': round(file_size / (1024 * 1024), 2),
                    'datetime': file_time.isoformat(),
                    'date': file_time.strftime('%Y-%m-%d %H:%M:%S')
                })
                total_size += file_size
            
            # æŒ‰æ—¶é—´æ’åºï¼ˆæœ€æ–°çš„åœ¨å‰ï¼‰
            backups.sort(key=lambda x: x['datetime'], reverse=True)
            
            return backups, total_size
            
        except Exception as e:
            print(f"âš ï¸  åˆ—å‡ºå¤‡ä»½å¤±è´¥: {e}")
            return [], 0
    
    def show_statistics(self):
        """æ˜¾ç¤ºå¤‡ä»½ç»Ÿè®¡ä¿¡æ¯"""
        backups, total_size = self.list_backups()
        total_size_mb = total_size / (1024 * 1024)
        
        print("\n" + "=" * 60)
        print("ğŸ“Š å¤‡ä»½ç»Ÿè®¡ä¿¡æ¯")
        print("=" * 60)
        print(f"å¤‡ä»½ç›®å½•: {self.backup_dir}")
        print(f"å¤‡ä»½æ–‡ä»¶æ•°: {len(backups)}")
        print(f"æ€»å¤§å°: {total_size_mb:.2f} MB ({total_size:,} å­—èŠ‚)")
        print(f"ä¿ç•™å¤©æ•°: {self.retention_days} å¤©")
        
        if backups:
            print(f"\næœ€æ–°å¤‡ä»½:")
            for i, backup in enumerate(backups[:5], 1):
                print(f"  {i}. {backup['filename']}")
                print(f"     æ—¶é—´: {backup['date']}")
                print(f"     å¤§å°: {backup['size_mb']} MB")
        
        print("=" * 60)


def main():
    """ä¸»å‡½æ•°"""
    import argparse
    
    parser = argparse.ArgumentParser(description='PostgreSQLæ•°æ®åº“å¤‡ä»½å·¥å…·')
    parser.add_argument('--backup', action='store_true', help='æ‰§è¡Œå¤‡ä»½')
    parser.add_argument('--type', choices=['full', 'schema', 'data'], default='full',
                       help='å¤‡ä»½ç±»å‹: full(å®Œæ•´), schema(ä»…ç»“æ„), data(ä»…æ•°æ®)')
    parser.add_argument('--cleanup', action='store_true', help='æ¸…ç†æ—§å¤‡ä»½')
    parser.add_argument('--list', action='store_true', help='åˆ—å‡ºæ‰€æœ‰å¤‡ä»½')
    parser.add_argument('--stats', action='store_true', help='æ˜¾ç¤ºç»Ÿè®¡ä¿¡æ¯')
    parser.add_argument('--backup-dir', help='å¤‡ä»½ç›®å½•è·¯å¾„')
    parser.add_argument('--retention-days', type=int, help='ä¿ç•™å¤©æ•°')
    
    args = parser.parse_args()
    
    # å¦‚æœæ²¡æœ‰æŒ‡å®šä»»ä½•æ“ä½œï¼Œé»˜è®¤æ‰§è¡Œå¤‡ä»½
    if not any([args.backup, args.cleanup, args.list, args.stats]):
        args.backup = True
    
    # åˆ›å»ºå¤‡ä»½ç®¡ç†å™¨
    backup_manager = PostgreSQLBackup(
        backup_dir=args.backup_dir,
        retention_days=args.retention_days
    )
    
    print("=" * 60)
    print("ğŸ—„ï¸  PostgreSQLæ•°æ®åº“å¤‡ä»½å·¥å…·")
    print("=" * 60)
    print(f"æ•°æ®åº“: {backup_manager.db_name}")
    print(f"ç”¨æˆ·: {backup_manager.db_user}")
    print(f"ä¸»æœº: {backup_manager.db_host}:{backup_manager.db_port}")
    print(f"å¤‡ä»½ç›®å½•: {backup_manager.backup_dir}")
    print("=" * 60)
    print()
    
    # æ‰§è¡Œå¤‡ä»½
    if args.backup:
        backup_info = backup_manager.backup_database(backup_type=args.type)
        if backup_info:
            print("\nâœ… å¤‡ä»½ä»»åŠ¡å®Œæˆ")
        else:
            print("\nâŒ å¤‡ä»½ä»»åŠ¡å¤±è´¥")
            sys.exit(1)
    
    # æ¸…ç†æ—§å¤‡ä»½
    if args.cleanup:
        backup_manager.cleanup_old_backups()
    
    # åˆ—å‡ºå¤‡ä»½
    if args.list:
        backups, total_size = backup_manager.list_backups()
        total_size_mb = total_size / (1024 * 1024)
        print(f"\nğŸ“‹ å¤‡ä»½æ–‡ä»¶åˆ—è¡¨ (å…± {len(backups)} ä¸ª, æ€»è®¡ {total_size_mb:.2f} MB):")
        for i, backup in enumerate(backups, 1):
            print(f"  {i}. {backup['filename']}")
            print(f"     æ—¶é—´: {backup['date']}")
            print(f"     å¤§å°: {backup['size_mb']} MB")
    
    # æ˜¾ç¤ºç»Ÿè®¡ä¿¡æ¯
    if args.stats:
        backup_manager.show_statistics()


if __name__ == '__main__':
    main()
